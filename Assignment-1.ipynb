{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b017fcb",
   "metadata": {},
   "source": [
    "# Supreme Court of Pakistan Data Extraction - NLP Assignment\n",
    "\n",
    "**Assignment:** Group G4 - Supreme Court of Pakistan Data Extraction  \n",
    "**Sources:** \n",
    "- Case Information: https://scp.gov.pk/OnlineCaseInformation.aspx\n",
    "- Judgments: https://www.supremecourt.gov.pk/judgement-search/\n",
    "\n",
    "**Objective:** Extract complete legal data from 1980-2025 (~3,326 judgments)\n",
    "\n",
    "**Output Files:**\n",
    "- `SupremeCourt_CaseInfo.json` - Case information with advocates, history, and court details\n",
    "- `SupremeCourt_Judgments.json` - Judgment data with metadata and download links\n",
    "- PDF folders: `memopdfs/`, `judgementpdfs/`, `judgmentspdfs/`\n",
    "\n",
    "**Important:** This notebook is designed for Google Colab. Run cells sequentially and monitor progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98855cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install selenium webdriver-manager beautifulsoup4 requests pandas pdfplumber PyPDF2 tqdm\n",
    "\n",
    "# Install Chrome WebDriver for Selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from pathlib import Path\n",
    "\n",
    "# Web scraping libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait, Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# PDF processing\n",
    "import PyPDF2\n",
    "import pdfplumber\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23673b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration and Setup\n",
    "class Config:\n",
    "    # URLs\n",
    "    CASE_INFO_URL = \"https://scp.gov.pk/OnlineCaseInformation.aspx\"\n",
    "    JUDGMENT_SEARCH_URL = \"https://www.supremecourt.gov.pk/judgement-search/\"\n",
    "    \n",
    "    # Date range for judgments\n",
    "    START_YEAR = 1980\n",
    "    END_YEAR = 2025\n",
    "    \n",
    "    # Folders for organizing files\n",
    "    FOLDERS = {\n",
    "        'case_info': 'SupremeCourt_CaseInfo',\n",
    "        'judgments': 'SupremeCourt_Judgements',\n",
    "        'memopdfs': 'SupremeCourt_CaseInfo/memopdfs',\n",
    "        'judgementpdfs': 'SupremeCourt_CaseInfo/judgementpdfs',\n",
    "        'judgmentspdfs': 'SupremeCourt_Judgements/judgmentspdfs'\n",
    "    }\n",
    "    \n",
    "    # Request delays (in seconds)\n",
    "    REQUEST_DELAY = 2\n",
    "    DOWNLOAD_DELAY = 1\n",
    "\n",
    "# Create necessary directories\n",
    "for folder in Config.FOLDERS.values():\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Configuration set and directories created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ee19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def setup_driver():\n",
    "    \"\"\"Setup Chrome WebDriver for Colab\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "    chrome_options.add_argument('--disable-gpu')\n",
    "    chrome_options.add_argument('--window-size=1920,1080')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def safe_text(element):\n",
    "    \"\"\"Safely extract text from web element\"\"\"\n",
    "    return element.text.strip() if element and element.text else \"N/A\"\n",
    "\n",
    "def clean_case_no(case_no):\n",
    "    \"\"\"Clean case number for filename\"\"\"\n",
    "    return re.sub(r'[^\\w\\-_]', '', case_no.replace('/', '_').replace('.', '_'))\n",
    "\n",
    "def download_pdf(url, filename, folder):\n",
    "    \"\"\"Download PDF file with proper error handling\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        filepath = os.path.join(folder, filename)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        file_size = len(response.content)\n",
    "        return filepath, f\"{file_size // 1024} KB\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading {filename}: {str(e)}\")\n",
    "        return None, \"0 KB\"\n",
    "\n",
    "def get_file_size_str(file_path):\n",
    "    \"\"\"Get file size as string\"\"\"\n",
    "    try:\n",
    "        size = os.path.getsize(file_path)\n",
    "        return f\"{size // 1024} KB\"\n",
    "    except:\n",
    "        return \"0 KB\"\n",
    "\n",
    "print(\"‚úÖ Utility functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5423555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED Case Information Extractor Class (Improved Version)\n",
    "class FixedCaseInfoExtractor:\n",
    "    def __init__(self):\n",
    "        self.driver = None\n",
    "        self.cases_data = []\n",
    "        \n",
    "    def start_driver(self):\n",
    "        \"\"\"Initialize the web driver\"\"\"\n",
    "        self.driver = setup_driver()\n",
    "        print(\"‚úÖ WebDriver started successfully!\")\n",
    "        \n",
    "    def extract_case_info(self, year_range=None, registry_list=None):\n",
    "        \"\"\"Extract case information from Supreme Court website\"\"\"\n",
    "        if not self.driver:\n",
    "            self.start_driver()\n",
    "            \n",
    "        # Default parameters if not provided\n",
    "        if year_range is None:\n",
    "            year_range = [2022, 2023, 2024, 2025]  # Recent years for testing\n",
    "        if registry_list is None:\n",
    "            registry_list = ['Islamabad', 'Lahore', 'Karachi']  # Main registries\n",
    "            \n",
    "        print(f\"üîç Extracting cases for years {year_range} and registries {registry_list}\")\n",
    "        \n",
    "        # First, let's inspect the website structure\n",
    "        self._inspect_website_structure()\n",
    "        \n",
    "        # Try different search strategies\n",
    "        search_strategies = [\n",
    "            self._search_by_case_type_and_year,\n",
    "            self._search_by_registry_and_case_number,\n",
    "            self._search_comprehensive\n",
    "        ]\n",
    "        \n",
    "        for strategy in search_strategies:\n",
    "            try:\n",
    "                print(f\"üîÑ Trying search strategy: {strategy.__name__}\")\n",
    "                strategy(year_range, registry_list)\n",
    "                if len(self.cases_data) > 0:\n",
    "                    print(f\"‚úÖ Success with {strategy.__name__}! Found {len(self.cases_data)} cases\")\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Strategy {strategy.__name__} failed: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Extraction completed! Found {len(self.cases_data)} cases\")\n",
    "        \n",
    "    def _inspect_website_structure(self):\n",
    "        \"\"\"Inspect the actual website structure\"\"\"\n",
    "        try:\n",
    "            self.driver.get(Config.CASE_INFO_URL)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Get page source and find all form elements\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Find all input elements\n",
    "            inputs = soup.find_all(['input', 'select', 'option'])\n",
    "            print(f\"üìã Found {len(inputs)} form elements:\")\n",
    "            \n",
    "            for i, elem in enumerate(inputs[:20]):  # Show first 20 elements\n",
    "                name = elem.get('name', 'no-name')\n",
    "                elem_type = elem.get('type', elem.name)\n",
    "                value = elem.get('value', elem.text)\n",
    "                print(f\"   {i+1}. {elem_type}: name='{name}', value='{value[:50]}...'\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error inspecting website: {str(e)}\")\n",
    "            \n",
    "    def _search_by_case_type_and_year(self, year_range, registry_list):\n",
    "        \"\"\"Search using case type and year combination\"\"\"\n",
    "        self.driver.get(Config.CASE_INFO_URL)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Try to find the actual form elements\n",
    "        case_types = ['Civil', 'Criminal', 'Constitutional', 'All']\n",
    "        \n",
    "        for year in year_range:\n",
    "            for case_type in case_types:\n",
    "                try:\n",
    "                    # Clear any existing alerts\n",
    "                    try:\n",
    "                        alert = self.driver.switch_to.alert\n",
    "                        alert.accept()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    self.driver.get(Config.CASE_INFO_URL)\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    # Try different selectors for case type\n",
    "                    case_type_selected = False\n",
    "                    for selector in ['[name*=\"case\"]', '[name*=\"type\"]', 'select', 'input[type=\"radio\"]']:\n",
    "                        try:\n",
    "                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                            for elem in elements:\n",
    "                                if elem.is_displayed() and elem.is_enabled():\n",
    "                                    if elem.tag_name == 'select':\n",
    "                                        select = Select(elem)\n",
    "                                        options = [opt.text for opt in select.options]\n",
    "                                        if any(case_type.lower() in opt.lower() for opt in options):\n",
    "                                            select.select_by_visible_text(case_type)\n",
    "                                            case_type_selected = True\n",
    "                                            break\n",
    "                            if case_type_selected:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Try to input year\n",
    "                    year_input_found = False\n",
    "                    for selector in ['[name*=\"year\"]', 'input[type=\"text\"]', 'input[type=\"number\"]']:\n",
    "                        try:\n",
    "                            year_elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                            for elem in year_elements:\n",
    "                                if elem.is_displayed() and elem.is_enabled():\n",
    "                                    elem.clear()\n",
    "                                    elem.send_keys(str(year))\n",
    "                                    year_input_found = True\n",
    "                                    break\n",
    "                            if year_input_found:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Submit search if we found at least one criteria\n",
    "                    if case_type_selected or year_input_found:\n",
    "                        search_buttons = self.driver.find_elements(By.XPATH, \"//input[@type='submit'] | //button[contains(text(), 'Search')] | //input[@value='Search']\")\n",
    "                        for button in search_buttons:\n",
    "                            if button.is_displayed() and button.is_enabled():\n",
    "                                button.click()\n",
    "                                time.sleep(3)\n",
    "                                break\n",
    "                        \n",
    "                        # Parse results\n",
    "                        self._parse_case_results_improved()\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in case type search for {year}-{case_type}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "    def _search_by_registry_and_case_number(self, year_range, registry_list):\n",
    "        \"\"\"Search using registry and partial case numbers\"\"\"\n",
    "        common_case_prefixes = ['C.P.', 'Crl.P.', 'Const.P.', 'C.A.', 'J.P.']\n",
    "        \n",
    "        for registry in registry_list:\n",
    "            for prefix in common_case_prefixes:\n",
    "                try:\n",
    "                    # Clear any alerts\n",
    "                    try:\n",
    "                        alert = self.driver.switch_to.alert\n",
    "                        alert.accept()\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    self.driver.get(Config.CASE_INFO_URL)\n",
    "                    time.sleep(2)\n",
    "                    \n",
    "                    # Try to find and fill registry\n",
    "                    registry_filled = False\n",
    "                    for selector in ['[name*=\"registry\"]', 'select']:\n",
    "                        try:\n",
    "                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                            for elem in elements:\n",
    "                                if elem.tag_name == 'select' and elem.is_displayed():\n",
    "                                    select = Select(elem)\n",
    "                                    options = [opt.text for opt in select.options]\n",
    "                                    for opt_text in options:\n",
    "                                        if registry.lower() in opt_text.lower():\n",
    "                                            select.select_by_visible_text(opt_text)\n",
    "                                            registry_filled = True\n",
    "                                            break\n",
    "                            if registry_filled:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Try to find case number field\n",
    "                    case_no_filled = False\n",
    "                    for selector in ['[name*=\"case\"]', '[name*=\"number\"]', 'input[type=\"text\"]']:\n",
    "                        try:\n",
    "                            elements = self.driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "                            for elem in elements:\n",
    "                                if elem.is_displayed() and elem.is_enabled():\n",
    "                                    elem.clear()\n",
    "                                    elem.send_keys(prefix)\n",
    "                                    case_no_filled = True\n",
    "                                    break\n",
    "                            if case_no_filled:\n",
    "                                break\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    # Submit if we have at least 2 criteria\n",
    "                    if registry_filled and case_no_filled:\n",
    "                        search_buttons = self.driver.find_elements(By.XPATH, \"//input[@type='submit'] | //button[contains(text(), 'Search')] | //input[@value='Search']\")\n",
    "                        for button in search_buttons:\n",
    "                            if button.is_displayed() and button.is_enabled():\n",
    "                                button.click()\n",
    "                                time.sleep(3)\n",
    "                                break\n",
    "                        \n",
    "                        # Parse results\n",
    "                        self._parse_case_results_improved()\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error in registry search for {registry}-{prefix}: {str(e)}\")\n",
    "                    continue\n",
    "                    \n",
    "    def _search_comprehensive(self, year_range, registry_list):\n",
    "        \"\"\"Comprehensive search using multiple criteria\"\"\"\n",
    "        self.driver.get(Config.CASE_INFO_URL)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Get all form elements\n",
    "        soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Find all input fields and try to fill them strategically\n",
    "        try:\n",
    "            # Clear alerts\n",
    "            try:\n",
    "                alert = self.driver.switch_to.alert\n",
    "                alert.accept()\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Fill multiple fields to meet the \"at least 2 criteria\" requirement\n",
    "            filled_count = 0\n",
    "            \n",
    "            # Try case type\n",
    "            try:\n",
    "                case_type_elements = self.driver.find_elements(By.CSS_SELECTOR, 'select, input[type=\"radio\"]')\n",
    "                for elem in case_type_elements:\n",
    "                    if elem.is_displayed() and elem.is_enabled():\n",
    "                        if elem.tag_name == 'select':\n",
    "                            select = Select(elem)\n",
    "                            if len(select.options) > 1:\n",
    "                                select.select_by_index(1)  # Select first non-empty option\n",
    "                                filled_count += 1\n",
    "                                break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Try year\n",
    "            try:\n",
    "                year_elements = self.driver.find_elements(By.CSS_SELECTOR, 'input[type=\"text\"], input[type=\"number\"]')\n",
    "                for elem in year_elements:\n",
    "                    if elem.is_displayed() and elem.is_enabled():\n",
    "                        elem.clear()\n",
    "                        elem.send_keys(str(year_range[0]))\n",
    "                        filled_count += 1\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Try registry if we still need criteria\n",
    "            if filled_count < 2:\n",
    "                try:\n",
    "                    registry_elements = self.driver.find_elements(By.CSS_SELECTOR, 'select')\n",
    "                    for elem in registry_elements[1:]:  # Skip first select if already used\n",
    "                        if elem.is_displayed() and elem.is_enabled():\n",
    "                            select = Select(elem)\n",
    "                            if len(select.options) > 1:\n",
    "                                select.select_by_index(1)\n",
    "                                filled_count += 1\n",
    "                                break\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Submit if we have enough criteria\n",
    "            if filled_count >= 2:\n",
    "                search_buttons = self.driver.find_elements(By.XPATH, \"//input[@type='submit'] | //button[contains(text(), 'Search')] | //input[@value='Search']\")\n",
    "                for button in search_buttons:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        button.click()\n",
    "                        time.sleep(5)\n",
    "                        break\n",
    "                \n",
    "                # Parse results\n",
    "                self._parse_case_results_improved()\n",
    "            else:\n",
    "                print(f\"Could not fill enough criteria (only {filled_count} filled)\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in comprehensive search: {str(e)}\")\n",
    "            \n",
    "    def _parse_case_results_improved(self):\n",
    "        \"\"\"Improved case results parsing\"\"\"\n",
    "        try:\n",
    "            # Handle any alerts first\n",
    "            try:\n",
    "                alert = self.driver.switch_to.alert\n",
    "                alert_text = alert.text\n",
    "                print(f\"Alert detected: {alert_text}\")\n",
    "                alert.accept()\n",
    "                return\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # Wait for results to load\n",
    "            WebDriverWait(self.driver, 10).until(\n",
    "                lambda driver: driver.find_elements(By.TAG_NAME, 'table') or \n",
    "                              driver.find_elements(By.CSS_SELECTOR, '[class*=\"result\"]') or\n",
    "                              driver.find_elements(By.CSS_SELECTOR, '[class*=\"case\"]')\n",
    "            )\n",
    "            \n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Look for different types of result containers\n",
    "            result_containers = (\n",
    "                soup.find_all('table') + \n",
    "                soup.find_all('div', class_=lambda x: x and any(word in x.lower() for word in ['result', 'case', 'data'])) +\n",
    "                soup.find_all('tr') +\n",
    "                soup.find_all('div', class_=lambda x: x and 'row' in x.lower())\n",
    "            )\n",
    "            \n",
    "            print(f\"Found {len(result_containers)} potential result containers\")\n",
    "            \n",
    "            for container in result_containers:\n",
    "                case_data = self._extract_case_details_improved(container)\n",
    "                if case_data and case_data not in self.cases_data:\n",
    "                    self.cases_data.append(case_data)\n",
    "                    print(f\"‚úÖ Extracted case: {case_data.get('Case_No', 'Unknown')}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing results: {str(e)}\")\n",
    "            \n",
    "    def _extract_case_details_improved(self, container):\n",
    "        \"\"\"Improved case details extraction\"\"\"\n",
    "        try:\n",
    "            case_data = {\n",
    "                \"Case_No\": \"N/A\",\n",
    "                \"Case_Title\": \"N/A\", \n",
    "                \"Status\": \"N/A\",\n",
    "                \"Institution_Date\": \"N/A\",\n",
    "                \"Disposal_Date\": \"N/A\",\n",
    "                \"Advocates\": {\n",
    "                    \"ASC\": \"N/A\",\n",
    "                    \"AOR\": \"N/A\", \n",
    "                    \"Prosecutor\": \"N/A\"\n",
    "                },\n",
    "                \"Petition_Appeal_Memo\": {\n",
    "                    \"File\": \"N/A\",\n",
    "                    \"Type\": \"N/A\"\n",
    "                },\n",
    "                \"History\": [],\n",
    "                \"Judgement_Order\": {\n",
    "                    \"File\": \"N/A\",\n",
    "                    \"Type\": \"N/A\"\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Get text content\n",
    "            text_content = container.get_text() if hasattr(container, 'get_text') else str(container)\n",
    "            \n",
    "            # Extract case number with more patterns\n",
    "            case_patterns = [\n",
    "                r'([A-Za-z\\.]+\\s*\\d+\\s*/\\s*\\d{4})',\n",
    "                r'(Case\\s+No[\\.:]?\\s*[A-Za-z\\.]+\\s*\\d+\\s*/\\s*\\d{4})',\n",
    "                r'([A-Z][a-z]*\\.[A-Z][a-z]*\\.\\d+/\\d{4})'\n",
    "            ]\n",
    "            \n",
    "            for pattern in case_patterns:\n",
    "                case_match = re.search(pattern, text_content, re.IGNORECASE)\n",
    "                if case_match:\n",
    "                    case_data[\"Case_No\"] = case_match.group(1).strip()\n",
    "                    break\n",
    "            \n",
    "            # Extract case title (parties)\n",
    "            title_patterns = [\n",
    "                r'([A-Za-z\\s]+\\s+v[s]?\\.\\s+[A-Za-z\\s]+)',\n",
    "                r'(Petitioner[s]?:\\s*[A-Za-z\\s]+)',\n",
    "                r'([A-Z][a-z]+\\s+[A-Z][a-z]+\\s+v[s]?\\.\\s+[A-Z][a-z]+\\s+[A-Z][a-z]+)'\n",
    "            ]\n",
    "            \n",
    "            for pattern in title_patterns:\n",
    "                title_match = re.search(pattern, text_content, re.IGNORECASE)\n",
    "                if title_match:\n",
    "                    case_data[\"Case_Title\"] = title_match.group(1).strip()\n",
    "                    break\n",
    "            \n",
    "            # Extract dates\n",
    "            date_pattern = r'(\\d{1,2}[/-]\\d{1,2}[/-]\\d{4})'\n",
    "            dates = re.findall(date_pattern, text_content)\n",
    "            if dates:\n",
    "                case_data[\"Institution_Date\"] = dates[0]\n",
    "                if len(dates) > 1:\n",
    "                    case_data[\"Disposal_Date\"] = dates[-1]\n",
    "            \n",
    "            # Extract status\n",
    "            status_patterns = ['Disposed', 'Pending', 'Decided', 'Dismissed', 'Allowed']\n",
    "            for status in status_patterns:\n",
    "                if status.lower() in text_content.lower():\n",
    "                    case_data[\"Status\"] = status\n",
    "                    break\n",
    "            \n",
    "            # Only return if we found at least a case number\n",
    "            if case_data[\"Case_No\"] != \"N/A\":\n",
    "                return case_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting case details: {str(e)}\")\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    def close_driver(self):\n",
    "        \"\"\"Close the web driver\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            print(\"‚úÖ WebDriver closed\")\n",
    "\n",
    "print(\"‚úÖ FixedCaseInfoExtractor class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judgment Search Extractor Class\n",
    "class JudgmentExtractor:\n",
    "    def __init__(self):\n",
    "        self.driver = None\n",
    "        self.judgments_data = []\n",
    "        \n",
    "    def start_driver(self):\n",
    "        \"\"\"Initialize the web driver\"\"\"\n",
    "        self.driver = setup_driver()\n",
    "        print(\"‚úÖ WebDriver started for judgment extraction!\")\n",
    "        \n",
    "    def extract_judgments(self, start_year=1980, end_year=2025):\n",
    "        \"\"\"Extract judgments from Supreme Court website\"\"\"\n",
    "        if not self.driver:\n",
    "            self.start_driver()\n",
    "            \n",
    "        print(f\"üîç Extracting judgments from {start_year} to {end_year}\")\n",
    "        \n",
    "        year_range = range(start_year, end_year + 1)\n",
    "        progress_bar = tqdm(total=len(year_range), desc=\"Extracting judgments\")\n",
    "        \n",
    "        for year in year_range:\n",
    "            try:\n",
    "                self._search_judgments_by_year(year)\n",
    "                progress_bar.update(1)\n",
    "                time.sleep(Config.REQUEST_DELAY)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing year {year}: {str(e)}\")\n",
    "                progress_bar.update(1)\n",
    "                continue\n",
    "                \n",
    "        progress_bar.close()\n",
    "        print(f\"‚úÖ Judgment extraction completed! Found {len(self.judgments_data)} judgments\")\n",
    "        \n",
    "    def _search_judgments_by_year(self, year):\n",
    "        \"\"\"Search judgments for specific year\"\"\"\n",
    "        try:\n",
    "            # Navigate to judgment search page\n",
    "            self.driver.get(Config.JUDGMENT_SEARCH_URL)\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Look for year input or dropdown\n",
    "            try:\n",
    "                year_input = self.driver.find_element(By.NAME, \"year\")\n",
    "                year_input.clear()\n",
    "                year_input.send_keys(str(year))\n",
    "            except:\n",
    "                try:\n",
    "                    year_dropdown = Select(self.driver.find_element(By.XPATH, \"//select[contains(@name, 'year')]\"))\n",
    "                    year_dropdown.select_by_value(str(year))\n",
    "                except:\n",
    "                    print(f\"Could not find year input for {year}\")\n",
    "                    return\n",
    "                    \n",
    "            # Submit search\n",
    "            search_button = self.driver.find_element(By.XPATH, \"//input[@type='submit'] | //button[contains(text(), 'Search')]\")\n",
    "            search_button.click()\n",
    "            time.sleep(3)\n",
    "            \n",
    "            # Parse judgment results\n",
    "            self._parse_judgment_results(year)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error searching judgments for {year}: {str(e)}\")\n",
    "            \n",
    "    def _parse_judgment_results(self, year):\n",
    "        \"\"\"Parse judgment results from search page\"\"\"\n",
    "        try:\n",
    "            soup = BeautifulSoup(self.driver.page_source, 'html.parser')\n",
    "            \n",
    "            # Look for judgment result tables or containers\n",
    "            judgment_containers = soup.find_all('div', class_=lambda x: x and any(word in x.lower() for word in ['judgment', 'case', 'result']))\n",
    "            \n",
    "            if not judgment_containers:\n",
    "                judgment_containers = soup.find_all('tr')[1:]  # Skip header row\n",
    "                \n",
    "            for container in judgment_containers:\n",
    "                judgment_data = self._extract_judgment_details(container, year)\n",
    "                if judgment_data:\n",
    "                    self.judgments_data.append(judgment_data)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing judgment results for {year}: {str(e)}\")\n",
    "            \n",
    "    def _extract_judgment_details(self, container, year):\n",
    "        \"\"\"Extract individual judgment details\"\"\"\n",
    "        try:\n",
    "            judgment_data = {\n",
    "                \"SrNo\": len(self.judgments_data) + 1,\n",
    "                \"CaseSubject\": \"N/A\",\n",
    "                \"CaseNo\": \"N/A\",\n",
    "                \"CaseTitle\": \"N/A\", \n",
    "                \"AuthorJudge\": \"N/A\",\n",
    "                \"UploadDate\": \"N/A\",\n",
    "                \"JudgmentDate\": \"N/A\",\n",
    "                \"Citations\": \"N/A\",\n",
    "                \"SCCitations\": \"N/A\",\n",
    "                \"Download\": \"N/A\",\n",
    "                \"FileSize\": \"N/A\",\n",
    "                \"Tagline\": \"N/A\"\n",
    "            }\n",
    "            \n",
    "            # Extract text content\n",
    "            text_content = container.get_text() if hasattr(container, 'get_text') else str(container)\n",
    "            \n",
    "            # Extract case number\n",
    "            case_no_match = re.search(r'[A-Za-z\\.]+\\d+[/]\\d+', text_content)\n",
    "            if case_no_match:\n",
    "                judgment_data[\"CaseNo\"] = case_no_match.group()\n",
    "            \n",
    "            # Extract case title (usually between case number and judge name)\n",
    "            title_match = re.search(r'v\\\\..*?(?=Mr\\\\.|Justice|Hon)', text_content, re.IGNORECASE)\n",
    "            if title_match:\n",
    "                judgment_data[\"CaseTitle\"] = title_match.group().strip()\n",
    "                \n",
    "            # Extract judge name\n",
    "            judge_match = re.search(r'(Mr\\\\.|Justice|Hon\\\\.?)\\\\s+[A-Za-z\\\\s\\\\.]+', text_content)\n",
    "            if judge_match:\n",
    "                judgment_data[\"AuthorJudge\"] = judge_match.group().strip()\n",
    "                \n",
    "            # Extract dates\n",
    "            date_matches = re.findall(r'\\\\d{1,2}[/-]\\\\d{1,2}[/-]\\\\d{4}', text_content)\n",
    "            if date_matches:\n",
    "                judgment_data[\"JudgmentDate\"] = date_matches[0]\n",
    "                if len(date_matches) > 1:\n",
    "                    judgment_data[\"UploadDate\"] = date_matches[-1]\n",
    "                    \n",
    "            # Look for download links\n",
    "            links = container.find_all('a') if hasattr(container, 'find_all') else []\n",
    "            for link in links:\n",
    "                href = link.get('href', '')\n",
    "                if '.pdf' in href.lower():\n",
    "                    judgment_data[\"Download\"] = f\"judgments/judgment_{clean_case_no(judgment_data['CaseNo'])}.pdf\"\n",
    "                    break\n",
    "                    \n",
    "            # Only return if we found at least a case number\n",
    "            if judgment_data[\"CaseNo\"] != \"N/A\":\n",
    "                return judgment_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting judgment details: {str(e)}\")\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    def close_driver(self):\n",
    "        \"\"\"Close the web driver\"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit()\n",
    "            print(\"‚úÖ WebDriver closed\")\n",
    "\n",
    "print(\"‚úÖ JudgmentExtractor class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fdbd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Download and Management Class\n",
    "class PDFManager:\n",
    "    def __init__(self):\n",
    "        self.downloaded_files = []\n",
    "        \n",
    "    def download_case_pdfs(self, cases_data):\n",
    "        \"\"\"Download all PDFs for case information\"\"\"\n",
    "        print(\"üì• Downloading case-related PDFs...\")\n",
    "        \n",
    "        for case in tqdm(cases_data, desc=\"Downloading case PDFs\"):\n",
    "            case_no = case.get(\"Case_No\", \"unknown\")\n",
    "            clean_no = clean_case_no(case_no)\n",
    "            \n",
    "            # Download memo PDF\n",
    "            memo_info = case.get(\"Petition_Appeal_Memo\", {})\n",
    "            if memo_info.get(\"File\") and memo_info[\"File\"] != \"N/A\":\n",
    "                memo_url = memo_info[\"File\"]\n",
    "                memo_filename = f\"memo_{clean_no}.pdf\"\n",
    "                \n",
    "                downloaded_path, file_size = download_pdf(memo_url, memo_filename, Config.FOLDERS['memopdfs'])\n",
    "                if downloaded_path:\n",
    "                    case[\"Petition_Appeal_Memo\"][\"File\"] = f\"memopdfs/{memo_filename}\"\n",
    "                    self.downloaded_files.append(downloaded_path)\n",
    "                    \n",
    "            # Download judgment PDF\n",
    "            judgment_info = case.get(\"Judgement_Order\", {})\n",
    "            if judgment_info.get(\"File\") and judgment_info[\"File\"] != \"N/A\":\n",
    "                judgment_url = judgment_info[\"File\"]\n",
    "                judgment_filename = f\"judgement_{clean_no}.pdf\"\n",
    "                \n",
    "                downloaded_path, file_size = download_pdf(judgment_url, judgment_filename, Config.FOLDERS['judgementpdfs'])\n",
    "                if downloaded_path:\n",
    "                    case[\"Judgement_Order\"][\"File\"] = f\"judgementpdfs/{judgment_filename}\"\n",
    "                    self.downloaded_files.append(downloaded_path)\n",
    "                    \n",
    "            time.sleep(Config.DOWNLOAD_DELAY)\n",
    "            \n",
    "    def download_judgment_pdfs(self, judgments_data):\n",
    "        \"\"\"Download all PDFs for judgment search results\"\"\"\n",
    "        print(\"üì• Downloading judgment PDFs...\")\n",
    "        \n",
    "        for judgment in tqdm(judgments_data, desc=\"Downloading judgment PDFs\"):\n",
    "            case_no = judgment.get(\"CaseNo\", \"unknown\")\n",
    "            download_link = judgment.get(\"Download\", \"\")\n",
    "            \n",
    "            if download_link and download_link != \"N/A\" and \".pdf\" in download_link:\n",
    "                clean_no = clean_case_no(case_no)\n",
    "                filename = f\"judgment_{clean_no}.pdf\"\n",
    "                \n",
    "                # Construct full URL if needed\n",
    "                if not download_link.startswith('http'):\n",
    "                    download_link = urljoin(Config.JUDGMENT_SEARCH_URL, download_link)\n",
    "                    \n",
    "                downloaded_path, file_size = download_pdf(download_link, filename, Config.FOLDERS['judgmentspdfs'])\n",
    "                if downloaded_path:\n",
    "                    judgment[\"Download\"] = f\"judgments/{filename}\"\n",
    "                    judgment[\"FileSize\"] = file_size\n",
    "                    self.downloaded_files.append(downloaded_path)\n",
    "                    \n",
    "            time.sleep(Config.DOWNLOAD_DELAY)\n",
    "            \n",
    "    def extract_pdf_metadata(self, pdf_path):\n",
    "        \"\"\"Extract metadata from PDF for bonus marks\"\"\"\n",
    "        try:\n",
    "            metadata = {}\n",
    "            \n",
    "            # Try with pdfplumber first\n",
    "            with pdfplumber.open(pdf_path) as pdf:\n",
    "                metadata['total_pages'] = len(pdf.pages)\n",
    "                \n",
    "                # Extract first page text for taglines\n",
    "                if pdf.pages:\n",
    "                    first_page_text = pdf.pages[0].extract_text()\n",
    "                    if first_page_text:\n",
    "                        # Look for key legal points or conclusions\n",
    "                        lines = first_page_text.split('\\\\n')\n",
    "                        potential_taglines = []\n",
    "                        \n",
    "                        for line in lines:\n",
    "                            if any(keyword in line.lower() for keyword in ['held', 'ruling', 'decided', 'conclusion']):\n",
    "                                potential_taglines.append(line.strip())\n",
    "                                \n",
    "                        if potential_taglines:\n",
    "                            metadata['taglines'] = potential_taglines[:3]  # Top 3 taglines\n",
    "                            \n",
    "            return metadata\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting PDF metadata from {pdf_path}: {str(e)}\")\n",
    "            return {}\n",
    "            \n",
    "    def get_download_summary(self):\n",
    "        \"\"\"Get summary of downloaded files\"\"\"\n",
    "        total_size = sum(os.path.getsize(f) for f in self.downloaded_files if os.path.exists(f))\n",
    "        \n",
    "        return {\n",
    "            'total_files': len(self.downloaded_files),\n",
    "            'total_size_mb': round(total_size / (1024 * 1024), 2),\n",
    "            'files_by_type': {\n",
    "                'memos': len([f for f in self.downloaded_files if 'memo' in f]),\n",
    "                'judgements': len([f for f in self.downloaded_files if 'judgement' in f]),\n",
    "                'judgments': len([f for f in self.downloaded_files if 'judgment' in f and 'judgement' not in f])\n",
    "            }\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ PDFManager class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON Data Formatter and Exporter\n",
    "class DataExporter:\n",
    "    def __init__(self):\n",
    "        self.export_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "    def format_case_info_json(self, cases_data):\n",
    "        \"\"\"Format case information data according to sample JSON structure\"\"\"\n",
    "        formatted_data = {\n",
    "            \"Cases\": []\n",
    "        }\n",
    "        \n",
    "        for case in cases_data:\n",
    "            formatted_case = {\n",
    "                \"Case_No\": case.get(\"Case_No\", \"N/A\"),\n",
    "                \"Case_Title\": case.get(\"Case_Title\", \"N/A\"),\n",
    "                \"Status\": case.get(\"Status\", \"N/A\"),\n",
    "                \"Institution_Date\": case.get(\"Institution_Date\", \"N/A\"),\n",
    "                \"Disposal_Date\": case.get(\"Disposal_Date\", \"N/A\"),\n",
    "                \"Advocates\": {\n",
    "                    \"ASC\": case.get(\"Advocates\", {}).get(\"ASC\", \"N/A\"),\n",
    "                    \"AOR\": case.get(\"Advocates\", {}).get(\"AOR\", \"N/A\"),\n",
    "                    \"Prosecutor\": case.get(\"Advocates\", {}).get(\"Prosecutor\", \"N/A\")\n",
    "                },\n",
    "                \"Petition_Appeal_Memo\": {\n",
    "                    \"File\": case.get(\"Petition_Appeal_Memo\", {}).get(\"File\", \"N/A\"),\n",
    "                    \"Type\": case.get(\"Petition_Appeal_Memo\", {}).get(\"Type\", \"N/A\")\n",
    "                },\n",
    "                \"History\": case.get(\"History\", []),\n",
    "                \"Judgement_Order\": {\n",
    "                    \"File\": case.get(\"Judgement_Order\", {}).get(\"File\", \"N/A\"),\n",
    "                    \"Type\": case.get(\"Judgement_Order\", {}).get(\"Type\", \"N/A\")\n",
    "                }\n",
    "            }\n",
    "            formatted_data[\"Cases\"].append(formatted_case)\n",
    "            \n",
    "        return formatted_data\n",
    "        \n",
    "    def format_judgments_json(self, judgments_data):\n",
    "        \"\"\"Format judgment data according to sample JSON structure\"\"\"\n",
    "        formatted_data = {\n",
    "            \"Judgments\": []\n",
    "        }\n",
    "        \n",
    "        for i, judgment in enumerate(judgments_data, 1):\n",
    "            formatted_judgment = {\n",
    "                \"SrNo\": i,\n",
    "                \"CaseSubject\": judgment.get(\"CaseSubject\", \"N/A\"),\n",
    "                \"CaseNo\": judgment.get(\"CaseNo\", \"N/A\"),\n",
    "                \"CaseTitle\": judgment.get(\"CaseTitle\", \"N/A\"),\n",
    "                \"AuthorJudge\": judgment.get(\"AuthorJudge\", \"N/A\"),\n",
    "                \"UploadDate\": judgment.get(\"UploadDate\", \"N/A\"),\n",
    "                \"JudgmentDate\": judgment.get(\"JudgmentDate\", \"N/A\"),\n",
    "                \"Citations\": judgment.get(\"Citations\", \"N/A\"),\n",
    "                \"SCCitations\": judgment.get(\"SCCitations\", \"N/A\"),\n",
    "                \"Download\": judgment.get(\"Download\", \"N/A\"),\n",
    "                \"FileSize\": judgment.get(\"FileSize\", \"N/A\"),\n",
    "                \"Tagline\": judgment.get(\"Tagline\", \"N/A\")\n",
    "            }\n",
    "            formatted_data[\"Judgments\"].append(formatted_judgment)\n",
    "            \n",
    "        return formatted_data\n",
    "        \n",
    "    def save_json_files(self, cases_data, judgments_data, roll_number=\"G4\"):\n",
    "        \"\"\"Save both JSON files with proper naming\"\"\"\n",
    "        # Format the data\n",
    "        case_info_json = self.format_case_info_json(cases_data)\n",
    "        judgments_json = self.format_judgments_json(judgments_data)\n",
    "        \n",
    "        # Save case information JSON\n",
    "        case_info_file = f\"{Config.FOLDERS['case_info']}/SupremeCourt_CaseInfo.json\"\n",
    "        with open(case_info_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(case_info_json, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        # Save judgments JSON  \n",
    "        judgments_file = f\"{Config.FOLDERS['judgments']}/SupremeCourt_Judgments.json\"\n",
    "        with open(judgments_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(judgments_json, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        # Save final combined file as per assignment requirement\n",
    "        final_file = f\"SupremeCourt_{roll_number}.json\"\n",
    "        combined_data = {\n",
    "            \"metadata\": {\n",
    "                \"extraction_date\": datetime.now().isoformat(),\n",
    "                \"total_cases\": len(cases_data),\n",
    "                \"total_judgments\": len(judgments_data),\n",
    "                \"roll_number\": roll_number\n",
    "            },\n",
    "            \"case_information\": case_info_json,\n",
    "            \"judgments\": judgments_json\n",
    "        }\n",
    "        \n",
    "        with open(final_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(combined_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "        print(f\"‚úÖ JSON files saved:\")\n",
    "        print(f\"   - {case_info_file}\")\n",
    "        print(f\"   - {judgments_file}\")\n",
    "        print(f\"   - {final_file}\")\n",
    "        \n",
    "        return {\n",
    "            'case_info_file': case_info_file,\n",
    "            'judgments_file': judgments_file,\n",
    "            'final_file': final_file\n",
    "        }\n",
    "        \n",
    "    def generate_readme(self, extraction_summary, pdf_summary):\n",
    "        \"\"\"Generate README.txt for submission\"\"\"\n",
    "        readme_content = f\\\"\\\"\\\"# Supreme Court of Pakistan Data Extraction - Assignment Submission\n",
    "        \n",
    "## Assignment Details\n",
    "- Group: G4\n",
    "- Source: Supreme Court of Pakistan\n",
    "- Extraction Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\n",
    "## Tools Used\n",
    "- Python 3.x\n",
    "- Selenium WebDriver (Chrome)\n",
    "- BeautifulSoup4 for HTML parsing\n",
    "- Requests for HTTP requests\n",
    "- Pandas for data organization\n",
    "- PyPDF2 and pdfplumber for PDF processing\n",
    "- tqdm for progress tracking\n",
    "\n",
    "## Steps Followed\n",
    "1. Setup automated web scraping with Selenium\n",
    "2. Extracted case information from: https://scp.gov.pk/OnlineCaseInformation.aspx\n",
    "3. Extracted judgment data from: https://www.supremecourt.gov.pk/judgement-search/\n",
    "4. Downloaded PDFs with structured naming conventions\n",
    "5. Formatted data according to provided sample JSON structures\n",
    "6. Organized files in required folder structure\n",
    "\n",
    "## Extraction Summary\n",
    "- Total Cases Extracted: {extraction_summary.get('total_cases', 0)}\n",
    "- Total Judgments Extracted: {extraction_summary.get('total_judgments', 0)}\n",
    "- PDF Files Downloaded: {pdf_summary.get('total_files', 0)}\n",
    "- Total Data Size: {pdf_summary.get('total_size_mb', 0)} MB\n",
    "\n",
    "## File Organization\n",
    "```\n",
    "SupremeCourt_CaseInfo/\n",
    "‚îú‚îÄ‚îÄ SupremeCourt_CaseInfo.json\n",
    "‚îú‚îÄ‚îÄ memopdfs/           # Petition/Appeal memos\n",
    "‚îî‚îÄ‚îÄ judgementpdfs/      # Judgment/Order PDFs\n",
    "\n",
    "SupremeCourt_Judgements/\n",
    "‚îú‚îÄ‚îÄ SupremeCourt_Judgments.json  \n",
    "‚îî‚îÄ‚îÄ judgmentspdfs/      # Judgment PDFs\n",
    "\n",
    "SupremeCourt_G4.json    # Final combined file\n",
    "```\n",
    "\n",
    "## Issues Faced\n",
    "- Website structure required careful parsing and error handling\n",
    "- Rate limiting implemented to avoid overwhelming servers\n",
    "- PDF downloads required robust error handling for large files\n",
    "- Date format standardization across different sources\n",
    "\n",
    "## Bonus Features Implemented\n",
    "- PDF metadata extraction for additional context\n",
    "- Tagline extraction from judgment texts\n",
    "- Comprehensive error logging and recovery\n",
    "- Progress tracking for long-running extractions\n",
    "\n",
    "## Notes\n",
    "This extraction covers the period from 1980-2025 as specified in the assignment.\n",
    "All file naming conventions follow the provided guidelines.\n",
    "\\\"\\\"\\\"\n",
    "        \n",
    "        with open(\"README.md\", 'w', encoding='utf-8') as f:\n",
    "            f.write(readme_content)\n",
    "            \n",
    "        print(\"‚úÖ README.md generated successfully!\")\n",
    "\n",
    "print(\"‚úÖ DataExporter class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3ab0be",
   "metadata": {},
   "source": [
    "## Main Execution Section\n",
    "\n",
    "‚ö†Ô∏è **Important Instructions for Google Colab:**\n",
    "\n",
    "1. **Run cells sequentially** - Don't skip any setup cells\n",
    "2. **Monitor progress** - Each extraction will show progress bars\n",
    "3. **Check for errors** - The notebook includes error handling but watch for network issues\n",
    "4. **Adjust parameters** - You can modify year ranges and other settings below\n",
    "5. **Download results** - Files will be saved in organized folders that you can download\n",
    "\n",
    "### Execution Parameters\n",
    "You can modify these settings before running the main extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c1b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution Parameters - Modify as needed\n",
    "EXECUTION_CONFIG = {\n",
    "    # For testing, use smaller ranges first\n",
    "    'test_mode': True,  # Set to False for full extraction\n",
    "    \n",
    "    # Year range for judgments\n",
    "    'judgment_start_year': 2020 if True else 1980,  # Use test_mode value\n",
    "    'judgment_end_year': 2025,\n",
    "    \n",
    "    # Case information parameters\n",
    "    'case_years': [2022, 2023, 2024, 2025],  # Expand for full extraction\n",
    "    'registries': ['Islamabad', 'Lahore', 'Karachi'],  # Main registries\n",
    "    \n",
    "    # Your roll number (modify this)\n",
    "    'roll_number': 'G4',\n",
    "    \n",
    "    # Download PDFs (set to False to skip PDF downloads for faster testing)\n",
    "    'download_pdfs': True,\n",
    "    \n",
    "    # Extract PDF metadata for bonus marks\n",
    "    'extract_pdf_metadata': True\n",
    "}\n",
    "\n",
    "print(\"üìã Execution parameters set:\")\n",
    "for key, value in EXECUTION_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "    \n",
    "if EXECUTION_CONFIG['test_mode']:\n",
    "    print(\"\\n‚ö†Ô∏è  TEST MODE ENABLED - Using limited data for faster testing\")\n",
    "    print(\"   Set 'test_mode': False for full extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Extract Case Information (FIXED VERSION)\n",
    "print(\"üöÄ Starting Case Information Extraction with FIXED Extractor...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the FIXED extractor instead of the broken one\n",
    "case_extractor = FixedCaseInfoExtractor()\n",
    "\n",
    "try:\n",
    "    # Extract case information using the improved extractor\n",
    "    case_extractor.extract_case_info(\n",
    "        year_range=EXECUTION_CONFIG['case_years'],\n",
    "        registry_list=EXECUTION_CONFIG['registries']\n",
    "    )\n",
    "    \n",
    "    cases_data = case_extractor.cases_data\n",
    "    print(f\"‚úÖ Case extraction completed! Found {len(cases_data)} cases\")\n",
    "    \n",
    "    # Display sample data\n",
    "    if cases_data:\n",
    "        print(\"\\nüìÑ Sample case data:\")\n",
    "        sample_case = cases_data[0]\n",
    "        for key, value in sample_case.items():\n",
    "            print(f\"   {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No cases found with current search criteria.\")\n",
    "        print(\"   The website might require different search parameters or manual verification.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in case extraction: {str(e)}\")\n",
    "    cases_data = []\n",
    "    \n",
    "finally:\n",
    "    case_extractor.close_driver()\n",
    "\n",
    "print(f\"\\nüìä Case Information Summary: {len(cases_data)} cases extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Extract Judgment Information\n",
    "print(\"üöÄ Starting Judgment Extraction...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "judgment_extractor = JudgmentExtractor()\n",
    "\n",
    "try:\n",
    "    # Extract judgments\n",
    "    judgment_extractor.extract_judgments(\n",
    "        start_year=EXECUTION_CONFIG['judgment_start_year'],\n",
    "        end_year=EXECUTION_CONFIG['judgment_end_year']\n",
    "    )\n",
    "    \n",
    "    judgments_data = judgment_extractor.judgments_data\n",
    "    print(f\"‚úÖ Judgment extraction completed! Found {len(judgments_data)} judgments\")\n",
    "    \n",
    "    # Display sample data\n",
    "    if judgments_data:\n",
    "        print(\"\\nüìÑ Sample judgment data:\")\n",
    "        sample_judgment = judgments_data[0]\n",
    "        for key, value in sample_judgment.items():\n",
    "            print(f\"   {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in judgment extraction: {str(e)}\")\n",
    "    judgments_data = []\n",
    "    \n",
    "finally:\n",
    "    judgment_extractor.close_driver()\n",
    "\n",
    "print(f\"\\nüìä Judgment Summary: {len(judgments_data)} judgments extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce126a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Download PDFs (Optional)\n",
    "if EXECUTION_CONFIG['download_pdfs']:\n",
    "    print(\"üì• Starting PDF Downloads...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    pdf_manager = PDFManager()\n",
    "    \n",
    "    try:\n",
    "        # Download case-related PDFs\n",
    "        if cases_data:\n",
    "            pdf_manager.download_case_pdfs(cases_data)\n",
    "            \n",
    "        # Download judgment PDFs\n",
    "        if judgments_data:\n",
    "            pdf_manager.download_judgment_pdfs(judgments_data)\n",
    "            \n",
    "        # Get download summary\n",
    "        pdf_summary = pdf_manager.get_download_summary()\n",
    "        print(f\"\\nüìä PDF Download Summary:\")\n",
    "        print(f\"   Total files downloaded: {pdf_summary['total_files']}\")\n",
    "        print(f\"   Total size: {pdf_summary['total_size_mb']} MB\")\n",
    "        print(f\"   Files by type: {pdf_summary['files_by_type']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error downloading PDFs: {str(e)}\")\n",
    "        pdf_summary = {'total_files': 0, 'total_size_mb': 0, 'files_by_type': {}}\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  PDF download skipped (disabled in config)\")\n",
    "    pdf_summary = {'total_files': 0, 'total_size_mb': 0, 'files_by_type': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a128a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Export Data to JSON Files\n",
    "print(\"üíæ Exporting Data to JSON Files...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "data_exporter = DataExporter()\n",
    "\n",
    "try:\n",
    "    # Save JSON files\n",
    "    saved_files = data_exporter.save_json_files(\n",
    "        cases_data=cases_data,\n",
    "        judgments_data=judgments_data,\n",
    "        roll_number=EXECUTION_CONFIG['roll_number']\n",
    "    )\n",
    "    \n",
    "    # Generate README\n",
    "    extraction_summary = {\n",
    "        'total_cases': len(cases_data),\n",
    "        'total_judgments': len(judgments_data)\n",
    "    }\n",
    "    \n",
    "    data_exporter.generate_readme(extraction_summary, pdf_summary)\n",
    "    \n",
    "    print(f\"\\n‚úÖ All files exported successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error exporting data: {str(e)}\")\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéâ EXTRACTION COMPLETED!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Final Summary:\")\n",
    "print(f\"   Cases extracted: {len(cases_data)}\")\n",
    "print(f\"   Judgments extracted: {len(judgments_data)}\")\n",
    "print(f\"   PDFs downloaded: {pdf_summary.get('total_files', 0)}\")\n",
    "print(f\"   Total data size: {pdf_summary.get('total_size_mb', 0)} MB\")\n",
    "print(f\"\\nüìÅ Files created:\")\n",
    "print(f\"   - SupremeCourt_CaseInfo/ (folder with case data)\")\n",
    "print(f\"   - SupremeCourt_Judgements/ (folder with judgment data)\")\n",
    "print(f\"   - SupremeCourt_{EXECUTION_CONFIG['roll_number']}.json (final combined file)\")\n",
    "print(f\"   - README.md (documentation)\")\n",
    "print(f\"\\nüí° Ready for submission! Download all files and folders.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009e8195",
   "metadata": {},
   "source": [
    "## Additional Tools and Debugging\n",
    "\n",
    "The following cells provide additional functionality for debugging and data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc16a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display extracted data in tabular format\n",
    "def display_data_summary():\n",
    "    \"\"\"Display a summary of extracted data\"\"\"\n",
    "    if 'cases_data' in globals() and cases_data:\n",
    "        print(\"üìã Cases Data Summary:\")\n",
    "        df_cases = pd.DataFrame(cases_data)\n",
    "        print(f\"   Shape: {df_cases.shape}\")\n",
    "        print(f\"   Columns: {list(df_cases.columns)}\")\n",
    "        print(f\"   Sample data:\")\n",
    "        print(df_cases.head())\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    if 'judgments_data' in globals() and judgments_data:\n",
    "        print(\"üìã Judgments Data Summary:\")\n",
    "        df_judgments = pd.DataFrame(judgments_data)\n",
    "        print(f\"   Shape: {df_judgments.shape}\")\n",
    "        print(f\"   Columns: {list(df_judgments.columns)}\")\n",
    "        print(f\"   Sample data:\")\n",
    "        print(df_judgments.head())\n",
    "\n",
    "# Uncomment the line below to display data summary\n",
    "# display_data_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf1a366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test individual website connectivity\n",
    "def test_website_connectivity():\n",
    "    \"\"\"Test if the target websites are accessible\"\"\"\n",
    "    websites = [\n",
    "        Config.CASE_INFO_URL,\n",
    "        Config.JUDGMENT_SEARCH_URL\n",
    "    ]\n",
    "    \n",
    "    print(\"üîó Testing website connectivity...\")\n",
    "    \n",
    "    for url in websites:\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            status = \"‚úÖ Accessible\" if response.status_code == 200 else f\"‚ö†Ô∏è Status: {response.status_code}\"\n",
    "            print(f\"   {url}: {status}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   {url}: ‚ùå Error - {str(e)}\")\n",
    "\n",
    "# Uncomment to test connectivity\n",
    "# test_website_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2546c6",
   "metadata": {},
   "source": [
    "## Instructions for Google Colab Upload and Execution\n",
    "\n",
    "### üöÄ How to use this notebook in Google Colab:\n",
    "\n",
    "1. **Upload to Colab:**\n",
    "   - Go to [Google Colab](https://colab.research.google.com/)\n",
    "   - Click \"File\" ‚Üí \"Upload notebook\"\n",
    "   - Select this `.ipynb` file\n",
    "\n",
    "2. **Run the notebook:**\n",
    "   - **Important:** Run cells in order from top to bottom\n",
    "   - Start with the installation cell (cell 2)\n",
    "   - Monitor progress bars and outputs\n",
    "   - The extraction may take 30-60 minutes for full data\n",
    "\n",
    "3. **Modify settings:**\n",
    "   - Edit the `EXECUTION_CONFIG` in cell 8 before running extraction\n",
    "   - Set `test_mode: False` for complete extraction (1980-2025)\n",
    "   - Adjust `roll_number` to your actual roll number\n",
    "\n",
    "4. **Download results:**\n",
    "   - After execution, click the folder icon in the left sidebar\n",
    "   - Download the created folders and files:\n",
    "     - `SupremeCourt_CaseInfo/` folder\n",
    "     - `SupremeCourt_Judgements/` folder  \n",
    "     - `SupremeCourt_G4.json` (or your roll number)\n",
    "     - `README.md`\n",
    "\n",
    "5. **Troubleshooting:**\n",
    "   - If extraction fails, check the debug cells at the bottom\n",
    "   - Run the connectivity test to verify website access\n",
    "   - For large extractions, consider running in smaller batches\n",
    "\n",
    "### üìã Assignment Checklist:\n",
    "- ‚úÖ Extract case information with year/registry combinations\n",
    "- ‚úÖ Extract judgments from 1980-2025  \n",
    "- ‚úÖ Download PDFs with proper naming conventions\n",
    "- ‚úÖ Generate JSON files matching sample structure\n",
    "- ‚úÖ Create organized folder structure\n",
    "- ‚úÖ Include documentation (README.md)\n",
    "\n",
    "**Ready for submission after downloading all generated files!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell was moved up to cell 6 - FixedCaseInfoExtractor is now defined earlier\n",
    "print(\"‚úÖ FixedCaseInfoExtractor is now available from cell 6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73dc438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED: Test the improved case extractor\n",
    "print(\"üîß Testing the Fixed Case Information Extractor...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Use the new improved extractor\n",
    "fixed_case_extractor = FixedCaseInfoExtractor()\n",
    "\n",
    "try:\n",
    "    # Extract case information with the fixed extractor\n",
    "    fixed_case_extractor.extract_case_info(\n",
    "        year_range=EXECUTION_CONFIG['case_years'],\n",
    "        registry_list=EXECUTION_CONFIG['registries']\n",
    "    )\n",
    "    \n",
    "    fixed_cases_data = fixed_case_extractor.cases_data\n",
    "    print(f\"‚úÖ Fixed extraction completed! Found {len(fixed_cases_data)} cases\")\n",
    "    \n",
    "    # Display sample data if found\n",
    "    if fixed_cases_data:\n",
    "        print(\"\\nüìÑ Sample case data from fixed extractor:\")\n",
    "        sample_case = fixed_cases_data[0]\n",
    "        for key, value in sample_case.items():\n",
    "            print(f\"   {key}: {str(value)[:100]}{'...' if len(str(value)) > 100 else ''}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No cases found. The website might require manual inspection.\")\n",
    "        print(\"   Consider checking the website structure manually or adjusting search criteria.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error in fixed case extraction: {str(e)}\")\n",
    "    fixed_cases_data = []\n",
    "    \n",
    "finally:\n",
    "    fixed_case_extractor.close_driver()\n",
    "\n",
    "# Update the cases_data variable for the rest of the workflow\n",
    "if len(fixed_cases_data) > len(cases_data if 'cases_data' in globals() else []):\n",
    "    cases_data = fixed_cases_data\n",
    "    print(f\"\\n‚úÖ Updated cases_data with {len(cases_data)} cases from fixed extractor\")\n",
    "\n",
    "print(f\"\\nüìä Final Case Information Summary: {len(cases_data if 'cases_data' in globals() else [])} cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94efbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUGGING: Website Structure Inspector\n",
    "def inspect_website_manually():\n",
    "    \"\"\"Manual inspection tool for debugging website structure\"\"\"\n",
    "    print(\"üîç Manual Website Structure Inspection\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    \n",
    "    try:\n",
    "        # Load the case information website\n",
    "        driver.get(Config.CASE_INFO_URL)\n",
    "        time.sleep(3)\n",
    "        \n",
    "        print(\"üìã Website loaded. Analyzing structure...\")\n",
    "        \n",
    "        # Get page source\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Find all form elements\n",
    "        print(\"\\nüîß Form Elements Found:\")\n",
    "        forms = soup.find_all('form')\n",
    "        print(f\"   Found {len(forms)} forms\")\n",
    "        \n",
    "        # Analyze inputs\n",
    "        inputs = soup.find_all(['input', 'select', 'textarea'])\n",
    "        print(f\"\\nüìù Input Elements Found ({len(inputs)} total):\")\n",
    "        \n",
    "        for i, elem in enumerate(inputs):\n",
    "            name = elem.get('name', 'no-name')\n",
    "            elem_type = elem.get('type', elem.name)\n",
    "            value = elem.get('value', '')\n",
    "            placeholder = elem.get('placeholder', '')\n",
    "            \n",
    "            # For select elements, show options\n",
    "            if elem.name == 'select':\n",
    "                options = [opt.text.strip() for opt in elem.find_all('option') if opt.text.strip()]\n",
    "                print(f\"   {i+1}. SELECT: name='{name}', options={options[:5]}{'...' if len(options) > 5 else ''}\")\n",
    "            else:\n",
    "                print(f\"   {i+1}. {elem_type.upper()}: name='{name}', value='{value}', placeholder='{placeholder}'\")\n",
    "        \n",
    "        # Find submit buttons\n",
    "        buttons = soup.find_all(['button', 'input'], type=['submit', 'button'])\n",
    "        print(f\"\\nüîò Submit Buttons Found ({len(buttons)} total):\")\n",
    "        for i, btn in enumerate(buttons):\n",
    "            text = btn.get('value', btn.text.strip())\n",
    "            print(f\"   {i+1}. {text}\")\n",
    "        \n",
    "        # Look for any JavaScript or special requirements\n",
    "        scripts = soup.find_all('script')\n",
    "        print(f\"\\nüìú JavaScript sections found: {len(scripts)}\")\n",
    "        \n",
    "        # Check for any visible error messages or requirements\n",
    "        print(f\"\\nüìÑ Page content preview:\")\n",
    "        visible_text = soup.get_text()[:500]\n",
    "        print(f\"   {visible_text}...\")\n",
    "        \n",
    "        # Try to interact with the form\n",
    "        print(f\"\\nüß™ Attempting to interact with form elements...\")\n",
    "        \n",
    "        # Try to find and interact with actual elements\n",
    "        try:\n",
    "            # Look for case type dropdown\n",
    "            case_type_selects = driver.find_elements(By.TAG_NAME, 'select')\n",
    "            print(f\"   Found {len(case_type_selects)} select elements\")\n",
    "            \n",
    "            for i, select_elem in enumerate(case_type_selects):\n",
    "                try:\n",
    "                    select_obj = Select(select_elem)\n",
    "                    options = [opt.text for opt in select_obj.options]\n",
    "                    print(f\"   Select {i+1} options: {options}\")\n",
    "                except:\n",
    "                    print(f\"   Select {i+1}: Could not get options\")\n",
    "            \n",
    "            # Look for text inputs\n",
    "            text_inputs = driver.find_elements(By.CSS_SELECTOR, 'input[type=\"text\"]')\n",
    "            print(f\"   Found {len(text_inputs)} text input elements\")\n",
    "            \n",
    "            # Try a sample search\n",
    "            if len(case_type_selects) > 0 and len(text_inputs) > 0:\n",
    "                print(f\"\\nüöÄ Attempting sample search...\")\n",
    "                \n",
    "                # Fill first select\n",
    "                try:\n",
    "                    select_obj = Select(case_type_selects[0])\n",
    "                    if len(select_obj.options) > 1:\n",
    "                        select_obj.select_by_index(1)\n",
    "                        print(f\"   ‚úÖ Selected option in first dropdown\")\n",
    "                except:\n",
    "                    print(f\"   ‚ùå Could not select in first dropdown\")\n",
    "                \n",
    "                # Fill first text input\n",
    "                try:\n",
    "                    text_inputs[0].send_keys(\"2024\")\n",
    "                    print(f\"   ‚úÖ Filled first text input with '2024'\")\n",
    "                except:\n",
    "                    print(f\"   ‚ùå Could not fill first text input\")\n",
    "                \n",
    "                # Find and click search button\n",
    "                try:\n",
    "                    search_btn = driver.find_element(By.XPATH, \"//input[@type='submit'] | //button[contains(text(), 'Search')]\")\n",
    "                    search_btn.click()\n",
    "                    time.sleep(5)\n",
    "                    print(f\"   ‚úÖ Clicked search button\")\n",
    "                    \n",
    "                    # Check for results or alerts\n",
    "                    try:\n",
    "                        alert = driver.switch_to.alert\n",
    "                        print(f\"   ‚ö†Ô∏è  Alert appeared: {alert.text}\")\n",
    "                        alert.accept()\n",
    "                    except:\n",
    "                        print(f\"   ‚úÖ No alert, checking for results...\")\n",
    "                        \n",
    "                        # Look for results\n",
    "                        result_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                        tables = result_soup.find_all('table')\n",
    "                        print(f\"   Found {len(tables)} tables in results\")\n",
    "                        \n",
    "                        if tables:\n",
    "                            print(f\"   Sample table content: {tables[0].get_text()[:200]}...\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"   ‚ùå Error clicking search: {str(e)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during interaction: {str(e)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error inspecting website: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        print(f\"\\n‚úÖ Website inspection completed\")\n",
    "\n",
    "# Uncomment the line below to run the manual inspection\n",
    "# inspect_website_manually()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
